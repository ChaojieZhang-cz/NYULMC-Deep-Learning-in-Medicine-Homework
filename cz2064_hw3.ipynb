{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine\n",
    "## BMSC-GA 4493, BMIN-GA 3007\n",
    "## Homework 3: RNNs\n",
    "\n",
    "Note 1: If you don't know how to run jupyter on the Prince cluster, here is another step-by-step guide here: \n",
    "<a href='https://docs.google.com/document/d/1HIdtzqJ6-RpsV0z2Gf5iXphNBTRca1kHZPlyqFxKpWs/edit?usp=sharing'> **Running Jupyter on the Cluster **</a>\n",
    "\n",
    "Note 2: If you need to write mathematical terms, you can type your answeres in a Markdown Cell via LaTex\n",
    "See: <a href=\"https://stackoverflow.com/questions/13208286/how-to-write-latex-in-ipython-notebook\">here</a> if you have issues. To see basic LaTex notation see: <a href=\"https://en.wikibooks.org/wiki/LaTeX/Mathematics\">here</a>.\n",
    "\n",
    "\n",
    "Submission instruction: Upload and Submit your final jupyter notebook file in newclasses.nyu.edu\n",
    "\n",
    "**Submission deadline: Thursday April 16th 2020 5pm.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Literature Review: DeepMod (Total points 20 + 10 bonus points)\n",
    "\n",
    "Read this paper:\n",
    "\n",
    "#### Qian Liu, Li Fang, Guoliang Yu, Depeng Wang, Chuan-Le Xiao & Kai Wang, _\"Detection of DNA base modifications by deep recurrent neural network on Oxford Nanopore sequencing data\"_ ,  Nature Communications, 2019 https://www.nature.com/articles/s41467-019-10168-2\n",
    "\n",
    "We are interested in understanding the task, the methods that is proposed in this publication, technical aspects of the implementation, and possible future work.\n",
    "\n",
    "**1.1) (5 points)** After you read the full article, go back to section **Methods**. Briefly describe the primary Deep Learning architecture used in DeepMod. Write the number of layers used, number of features input to the network?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The deep learing architecture used in DeepMod is bidirectional RNN with long short-term memory (LSTM) units. There are 3 hidden layers and 7 features input in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2) (5 points)** Describe the optional second deep neural network architecuture, including the number of layers and number of input features, number of nodes in hidden layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are four layers in the second deep neural network, including an input layer, two hidden layers, and an output layer. \n",
    "\n",
    "The input of the network is a 14-value vector.\n",
    "\n",
    "The first hidden layer has 100 hidden nodes, and the second hidden layer has 20 hidden nodes. Different layers were connected by full network with dropout (dropout rate = 0.7).\n",
    "\n",
    "The output layer has sigmoid activation for outputting final methylation percentage for a CpG site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3) (5 points)** What is the loss function used to train the primary network? \n",
    "\n",
    "What are the evaluation criteria used by the authors for all the tasks? (**Hint:** Look at Performance measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Loss Function: cross entropy loss\n",
    "\n",
    "Evaluation Criteria: accuracy, precision, recall, AP(weighted mean of precisions achieved at each threshold of predicted methylation percentage), and AUC(area under receiver operating characteristic curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4) (5 points)** Are there some data augmentation/regularization that authors have used? What are some techniques that could have been used and wasn't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The paper applies drop out in the second deep neural network. Other techniques can be L1/L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5) (Bonus maximum 10 points)**. What other architectures would you try? For each family of models, please do a literature search and see if a paper on that architecture for the task of DNA base modification has been used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Convolutional Neural Network, Deep Neural Network, Hidden Markov Model \n",
    "\n",
    "##### Convolutional Neural Network: \n",
    "DeepSignal: detecting DNA methylation state from Nanopore sequencing reads using deep-learning \n",
    "\n",
    "##### Perceptron Neural Network:\n",
    "Nanopore detection of bacterial DNA base modifications\n",
    "\n",
    "##### Hidden Markov Model \n",
    "Detecting DNA cytosine methylation using nanopore sequencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Literature Review: Self Attention (20 points + 10 bonus points)\n",
    "\n",
    "Read this paper: \n",
    "\n",
    "\n",
    "#### Xianlong Zeng, Yunyi Feng, Soheil Moosavinasab, Deborah Lin, Simon Lin, Chang Liu _\"Multilevel Self-Attention Model and its Use on Medical Risk Prediction\"_ https://psb.stanford.edu/psb-online/proceedings/psb20/Zeng.pdf\n",
    "\n",
    "After you read the paper, go back to Section 3.2 and 3.3. \n",
    "\n",
    "**2.1) (10 points)** Describe the architecture used in the paper to generate patient embedding. Please mention the architecture of self-attention units including any formula given in paper. Also include the input to the architecture.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### model architecture\n",
    "1. Model input: medical codes within each medical visit.\n",
    "2. Medical codes c of each visit are projected into a mdimensional continuous embedding space, and passed through the code-level self-attention encoder and aggregated into a visit embedding v.\n",
    "3. Each medical visit embedding v add its time embedding.\n",
    "4. Aggregate the visit vectors via the visit-level self-attention encoder, and formed the intermediate patient representation u.\n",
    "5. Concatenate the intermediate patient embedding u and demographic embedding, and  stacked three fully connected feedforward layers to obtain the patient embedding p.\n",
    "\n",
    "#### self-attention unitsï¼š\n",
    "1. A self-attention unit contains a self-attention layer, normalization layer and a feed forward residual connected layer.\n",
    "\n",
    "2. There are two self-attention units in the model, code-level and visit-level self-attention unit.\n",
    "\n",
    "$ S_c(c_k|c_1,c_2,...,c_j) = \\sigma_v(f(c_k + \\sum\\limits_{l=1}^{|v|}\\propto_{c_k c_l} c_k)) $\n",
    "\n",
    "$\\propto_{c_k*c_1},\\propto_{c_k*c_2},...,\\propto_{c_k*c_|v|} = softmax(\\frac{Q_{c_k} K_{c_1}}{\\sqrt{m}}, \\frac{Q_{c_k} K_{v_2}}{\\sqrt{m}},...,\\frac{Q_{c_k} K_{v_{|v|}}}{\\sqrt{m}}) $\n",
    "\n",
    "$Q_{c_k} = W_q c_k$\n",
    "    \n",
    "$K_{c_k} = W_k c_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) (5 points)** What are the different tasks that the architecture is used to solve? What are the Loss functions used for different tasks? What are the evaluation criteria for the different tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Disease prediction (multiclass classification task) and medical cost prediction (regression task). \n",
    "\n",
    "The paper uses negative log-likelihood loss function for disease prediction and mean-squared-error for cost prediction.\n",
    "\n",
    "Evaluation metric of cost prediction: mean absolute error\n",
    "\n",
    "Evaluation metric of disease prediction: Recall@k (defined as the number of successfully recalled medical codes from the k recalled codes divided by the number of true positive diagnosis codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3) (5 points)** In Section 5.2 What is the best model according to the evaluation criteria? How is it different from the second best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSAM(AUX) is the best model, MSAM is the second best model.\n",
    "\n",
    "MSAM with auxiliary task implement disease prediction, it mitigated the random nature of incurring the medical cost and stabilized the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4) (Bonus maximum 10 points)** What are some alternative architectures/Loss functions/Pretraining methods that you would recommend as followup work? Name 2 potential architectures, and in a few sentences explain why the proposed changes might work better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. BERT language representation model: BERT models are state-of-the-art models for a wide range of tasks, and achieve high score on GLUE Test. BERT use a bidirectional pre-training architecture, giving better performance than standard unidirectional language model.\n",
    "2. SmoothL1Loss can be used as loss function in cost prediction. Compared with mean squared error loss, smooth L1 loss is robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Programming: Build Classifiers on Medical Transcriptions - Recurrent Neural Networks and Self Attention(60 points + 10 bonus points)\n",
    "\n",
    "Let's build some models now. In this homework, we will focus on a dataset which has around 5000 medical transcriptions and the corresponding medical specialty. The data is available <a href=\"https://www.kaggle.com/tboyle10/medicaltranscriptions\">here</a>.\n",
    "\n",
    "Here, we will focus on predicting top few classes of medical specialty, from the transcription text. <a href=\"https://github.com/nyumc-dl/BMSC-GA-4493-Spring2020/tree/master/lab5\">Lab 5</a> will be very useful here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1) (5 points)** Read the csv using Pandas. Select the top 5 classes ('medical_specialty') from the data. Only keep the rows that belong to one of these classes in your data. Which classes are there, and how many rows do you have after this filteration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Surgery',\n",
       " ' Consult - History and Phy.',\n",
       " ' Cardiovascular / Pulmonary',\n",
       " ' Orthopedic',\n",
       " ' Radiology']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('mtsamples.csv',index_col=0)\n",
    "top_5_classes = df.groupby('medical_specialty').count().sort_values('sample_name',ascending=False)[:5].index.tolist()\n",
    "top_5_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 3</td>\n",
       "      <td>2-D ECHOCARDIOGRAM,Multiple views of the heart...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d echocardiogram...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Echocardiogram and Doppler</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 4</td>\n",
       "      <td>DESCRIPTION:,1.  Normal cardiac chambers size....</td>\n",
       "      <td>cardiovascular / pulmonary, ejection fraction,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Normal left ventricle, moderate biatrial enla...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Doppler</td>\n",
       "      <td>2-D STUDY,1. Mild aortic stenosis, widely calc...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d study, doppler...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  \\\n",
       "3                              2-D M-Mode. Doppler.     \n",
       "4                                  2-D Echocardiogram   \n",
       "7                                  2-D Echocardiogram   \n",
       "9                          Echocardiogram and Doppler   \n",
       "11   Normal left ventricle, moderate biatrial enla...   \n",
       "\n",
       "              medical_specialty               sample_name  \\\n",
       "3    Cardiovascular / Pulmonary   2-D Echocardiogram - 1    \n",
       "4    Cardiovascular / Pulmonary   2-D Echocardiogram - 2    \n",
       "7    Cardiovascular / Pulmonary   2-D Echocardiogram - 3    \n",
       "9    Cardiovascular / Pulmonary   2-D Echocardiogram - 4    \n",
       "11   Cardiovascular / Pulmonary              2-D Doppler    \n",
       "\n",
       "                                        transcription  \\\n",
       "3   2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4   1.  The left ventricular cavity size and wall ...   \n",
       "7   2-D ECHOCARDIOGRAM,Multiple views of the heart...   \n",
       "9   DESCRIPTION:,1.  Normal cardiac chambers size....   \n",
       "11  2-D STUDY,1. Mild aortic stenosis, widely calc...   \n",
       "\n",
       "                                             keywords  label  \n",
       "3   cardiovascular / pulmonary, 2-d m-mode, dopple...      2  \n",
       "4   cardiovascular / pulmonary, 2-d, doppler, echo...      2  \n",
       "7   cardiovascular / pulmonary, 2-d echocardiogram...      2  \n",
       "9   cardiovascular / pulmonary, ejection fraction,...      2  \n",
       "11  cardiovascular / pulmonary, 2-d study, doppler...      2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['medical_specialty'].apply(lambda x : x in top_5_classes),:]\n",
    "df = df.loc[df['transcription'].apply(lambda x : type(x) == str),:]\n",
    "df['label'] = df['medical_specialty'].apply(lambda x : top_5_classes.index(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 2603\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows:',len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2) (5 points)** Now convert your data into train, test and validation set. Shuffle the rows, and split them with ratios of (train:60%, valid:20%, test:20%). Set the random seed to 2020. Please follow the steps from https://pytorch.org/docs/stable/notes/randomness.html to set all the seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "def seed_torch(seed=2020):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "seed_torch(seed=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_val_data = train_test_split(df, test_size=0.40, random_state=2020)\n",
    "test_data, val_data = train_test_split(test_val_data, test_size=0.50, random_state=2020)\n",
    "train_data.index = np.arange(len(train_data))\n",
    "val_data.index = np.arange(len(val_data))\n",
    "test_data.index = np.arange(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3) (5 points)** Create a function to create vocabulary from the training data. Only use the transcription column for this. Use the tokenization scheme of your choice and create a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yz6432/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8714\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def build_vocab(sentences, min_count=3, max_vocab=None):\n",
    "    UNK = \"<UNK>\"\n",
    "    PAD = \"<PAD>\"\n",
    "    word_count = Counter()\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "        word_count.update(word_tokenize(sentence.lower()))\n",
    "    \n",
    "    vocabulary = list([w for w in word_count if word_count[w] > min_count]) + [UNK, PAD]\n",
    "    indices = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "    return vocabulary, indices\n",
    "\n",
    "vocabulary, vocab_indices = build_vocab(train_data['transcription'])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4) (10 points)** Write a dataloader and collate function so that we can begin to train our networks! You can choose to use either the complete transcription text or fix a maximum length of transcription text as input for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class mtDataset(Dataset):\n",
    "    def __init__(self, vocab_index, df, label = 'label'):\n",
    "        self.vocab_index = vocab_index\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        sentence = self.df.loc[key, 'transcription']\n",
    "        sentence = re.sub('[\\\\(\\[#.!?,\\'\\/\\])0-9]', ' ', sentence)\n",
    "        token_indices = np.array([self.vocab_index[word] if word in self.vocab_index else self.vocab_index['<UNK>'] for word in word_tokenize(sentence.lower())])\n",
    "        return (torch.tensor(token_indices) , self.df.loc[key, self.label])\n",
    "\n",
    "\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=len(vocabulary)-1)\n",
    "\n",
    "    return torch.as_tensor(xx_pad), torch.as_tensor(x_lens), torch.LongTensor(yy)\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 2\n",
    "train_loader = DataLoader(mtDataset(vocab_indices, train_data),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          collate_fn = pad_collate)\n",
    "val_loader = DataLoader(mtDataset(vocab_indices, val_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)\n",
    "test_loader = DataLoader(mtDataset(vocab_indices, test_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5) (10 points)** Now you are ready to build your sequence classification model!\n",
    "\n",
    "First, Build a simple GRU model that takes as input the text indices from the vocabulary, and ends with a softmax over total number of classes. Use the embedding and hidden dimension of your choice. \n",
    "\n",
    "**Please train your model to reach at the least 55% accuracy on the test set.**\n",
    "\n",
    "At each epoch, compute and print **Average Cross Entropy loss** and **Accuracy** on both **train and validation set** \n",
    "\n",
    "Plot your validation and train loss over different epochs. \n",
    "\n",
    "Plot your validation and train accuracies over different epochs. \n",
    "\n",
    "Finally print accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_dim=40, output_dim=5, vocab_size=len(vocabulary), embedding_dim=50, rnn='GRU'):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn_fn = rnn\n",
    "        assert self.rnn_fn in ['LSTM','GRU']\n",
    "        self.rnn = getattr(nn, rnn)(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        x = self.emb(x)\n",
    "        _, last_hidden = self.rnn(pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False))\n",
    "        if self.rnn_fn == 'LSTM':\n",
    "            last_hidden = last_hidden[0]\n",
    "        out = self.fc(last_hidden.view(-1, self.hidden_dim))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader=train_loader, val_loader=val_loader, learning_rate=1e-4, num_epoch=10):\n",
    "    start_time = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "    train_loss_return = []\n",
    "    train_acc_return = []\n",
    "    val_loss_return = []\n",
    "    val_acc_return = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        # Training steps\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        model.train()\n",
    "        train_loss_list = []\n",
    "        for i, (data, data_len, labels) in enumerate(train_loader):\n",
    "            data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "            outputs = model(data, data_len)\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            predictions += list(pred.cpu().numpy())\n",
    "            truths += list(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum()\n",
    "            model.zero_grad()\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            train_loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # report performance\n",
    "        acc = (100 * correct / total)\n",
    "        train_acc_return.append(acc)\n",
    "        train_loss_every_epoch = np.average(train_loss_list)\n",
    "        train_loss_return.append(train_loss_every_epoch)\n",
    "        print('----------Epoch{:2d}/{:2d}----------'.format(epoch+1,num_epoch))\n",
    "        print('Train set | Loss: {:6.4f} | Accuracy: {:4.2f}% '.format(train_loss_every_epoch, acc))\n",
    "        \n",
    "        # Evaluate after every epochh\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        val_loss_list = []\n",
    "        with torch.no_grad():\n",
    "            for i, (data, data_len, labels) in enumerate(val_loader):\n",
    "                data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "                outputs = model(data, data_len)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss_list.append(loss.item())\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "            # report performance\n",
    "            acc = (100 * correct / total)\n",
    "            val_acc_return.append(acc)\n",
    "            val_loss_every_epoch = np.average(val_loss_list)\n",
    "            val_loss_return.append(val_loss_every_epoch)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model_wts = model.state_dict()\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Test set | Loss: {:6.4f} | Accuracy: {:4.2f}% | time elapse: {:>9}'\\\n",
    "                  .format(val_loss_every_epoch, acc,elapse))\n",
    "    return model,train_loss_return,train_acc_return,val_loss_return,val_acc_return,best_model_wts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Epoch 1/10----------\n",
      "Train set | Loss: 1.5921 | Accuracy: 24.00% \n",
      "Test set | Loss: 1.4907 | Accuracy: 40.00% | time elapse:  00:00:32\n",
      "----------Epoch 2/10----------\n",
      "Train set | Loss: 1.4300 | Accuracy: 42.00% \n",
      "Test set | Loss: 1.3910 | Accuracy: 43.00% | time elapse:  00:01:04\n",
      "----------Epoch 3/10----------\n",
      "Train set | Loss: 1.3718 | Accuracy: 43.00% \n",
      "Test set | Loss: 1.3626 | Accuracy: 44.00% | time elapse:  00:01:36\n",
      "----------Epoch 4/10----------\n",
      "Train set | Loss: 1.3427 | Accuracy: 44.00% \n",
      "Test set | Loss: 1.3446 | Accuracy: 45.00% | time elapse:  00:02:09\n",
      "----------Epoch 5/10----------\n",
      "Train set | Loss: 1.3136 | Accuracy: 46.00% \n",
      "Test set | Loss: 1.3244 | Accuracy: 47.00% | time elapse:  00:02:41\n",
      "----------Epoch 6/10----------\n",
      "Train set | Loss: 1.2792 | Accuracy: 47.00% \n",
      "Test set | Loss: 1.2885 | Accuracy: 48.00% | time elapse:  00:03:13\n",
      "----------Epoch 7/10----------\n",
      "Train set | Loss: 1.2278 | Accuracy: 51.00% \n",
      "Test set | Loss: 1.2228 | Accuracy: 51.00% | time elapse:  00:03:46\n",
      "----------Epoch 8/10----------\n",
      "Train set | Loss: 1.1449 | Accuracy: 55.00% \n",
      "Test set | Loss: 1.1634 | Accuracy: 55.00% | time elapse:  00:04:18\n",
      "----------Epoch 9/10----------\n",
      "Train set | Loss: 1.1306 | Accuracy: 55.00% \n",
      "Test set | Loss: 1.1405 | Accuracy: 55.00% | time elapse:  00:04:50\n",
      "----------Epoch10/10----------\n",
      "Train set | Loss: 1.0926 | Accuracy: 58.00% \n",
      "Test set | Loss: 1.1374 | Accuracy: 57.00% | time elapse:  00:05:22\n"
     ]
    }
   ],
   "source": [
    "gru_model = RNN().to(device)\n",
    "model,train_loss,train_acc,val_loss,val_acc,best_model_wts = train(gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJMzRdjwI2uIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(train_loss,label='train loss')\n",
    "line2, = ax.plot(val_loss,label='validate loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGlNf6MsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(train_acc,label='train accuracy')\n",
    "line2, = ax.plot(val_acc,label='validate accuracy')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader=test_loader, best_model_wts = best_model_wts):\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    truths = []\n",
    "    test_loss_list = []  \n",
    "    with torch.no_grad():\n",
    "        for i, (data, data_len, labels) in enumerate(val_loader):\n",
    "            data, data_len, labels = data.to(device), data_len.to(device), labels.to(device)\n",
    "            outputs = model(data, data_len)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            test_loss_list.append(loss.item())\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            predictions += list(pred.cpu().numpy())\n",
    "            truths += list(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum()\n",
    "        acc = (100 * correct / total)\n",
    "        avg_test_loss = np.average(test_loss_list)\n",
    "        print('Test set | Loss: {:6.4f} | Accuracy: {:4.2f}% '.format(avg_test_loss, acc))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set | Loss: 1.1411 | Accuracy: 57.00% \n"
     ]
    }
   ],
   "source": [
    "test(gru_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6) (25 points)** Now, let's finetune a sequence classification model based on BERT. Please install the Huggingface's Transformers library for this. Use the Pretrained 'bert-base-uncased' model for this problem. Please use the BERT tokenizer from the pretrained built for 'bert-base-uncased' model . Use the AdamW optimizer from the transformers library for optimization. Remember BERT uses Attention masks for input so you need to create a separate dataloader for BERT. Please keep in mind that BERT can handle maximum of 512 tokens.\n",
    "\n",
    "**Please finetune the model so that it reaches at least 65% accuracy on the test set.**\n",
    "\n",
    "The rest of your experimental setting should be the same as 3.5:\n",
    "\n",
    "At each epoch, compute and print **Average Cross Entropy loss** and **Accuracy** on both **train and validation set** \n",
    "\n",
    "Plot your validation and train loss over different epochs. \n",
    "\n",
    "Plot your validation and train accuracies over different epochs. \n",
    "\n",
    "Finally print accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import transformers\n",
    "device = torch.device(\"cuda\")\n",
    "seed_torch(seed=2020)\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BERT_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer = tokenizer, label = 'label'):\n",
    "        self.df = df\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, 'transcription']\n",
    "        tokens_query = self.tokenizer.tokenize(text)\n",
    "        tokens_query = tokens_query[:510]\n",
    "        word_pieces = [\"[CLS]\"] + tokens_query + [\"[SEP]\"]\n",
    "        ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        item_label = self.df.loc[idx, self.label]\n",
    "        return (tokens_tensor,item_label)\n",
    "    \n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    tokens_tensors = pad_sequence(xx, batch_first=True)\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    return torch.as_tensor(tokens_tensors), torch.as_tensor(x_lens), masks_tensors, torch.LongTensor(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "train_loader = DataLoader(BERT_Dataset(train_data),\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          collate_fn = pad_collate)\n",
    "val_loader = DataLoader(BERT_Dataset(val_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)\n",
    "test_loader = DataLoader(BERT_Dataset(test_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed_torch(seed=2020)\n",
    "def train(model, train_loader=train_loader, val_loader=val_loader, learning_rate=2e-5, num_epoch=10):\n",
    "    start_time = time.time()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-06, weight_decay=0.0, correct_bias=True)\n",
    "    train_loss_return = []\n",
    "    train_acc_return = []\n",
    "    val_loss_return = []\n",
    "    val_acc_return = []\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        # Training steps\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        model.train()\n",
    "        train_loss_list = []\n",
    "        for i, (data, data_len, masks, labels) in enumerate(train_loader):\n",
    "            data,data_len,masks,labels=data.to(device),data_len.to(device),masks.to(device),labels.to(device)\n",
    "            outputs = model(data, attention_mask = masks)[0]\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            predictions += list(pred.cpu().numpy())\n",
    "            truths += list(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum()\n",
    "            model.zero_grad()\n",
    "            #loss = loss_fn(outputs.squeeze(), labels)\n",
    "            loss = model(data, attention_mask = masks, labels=labels)[0]\n",
    "            train_loss_list.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # report performance\n",
    "        acc = (100 * correct / total)\n",
    "        train_acc_return.append(acc)\n",
    "        train_loss_every_epoch = np.average(train_loss_list)\n",
    "        train_loss_return.append(train_loss_every_epoch)\n",
    "        print('----------Epoch{:2d}/{:2d}----------'.format(epoch+1,num_epoch))\n",
    "        print('Train set | Loss: {:6.4f} | Accuracy: {:4.2f}% '.format(train_loss_every_epoch, acc))\n",
    "        \n",
    "        # Evaluate after every epochh\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        truths = []\n",
    "        val_loss_list = []\n",
    "        with torch.no_grad():\n",
    "            for i, (data, data_len, masks, labels) in enumerate(val_loader):\n",
    "                data,data_len,masks,labels=data.to(device),data_len.to(device),masks.to(device),labels.to(device)\n",
    "                outputs = model(data)[0]\n",
    "                #loss = loss_fn(outputs.squeeze(), labels)\n",
    "                loss = model(data, attention_mask = masks, labels=labels)[0]\n",
    "                val_loss_list.append(loss.item())\n",
    "                pred = outputs.data.max(-1)[1]\n",
    "                predictions += list(pred.cpu().numpy())\n",
    "                truths += list(labels.cpu().numpy())\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum()\n",
    "            # report performance\n",
    "            acc = (100 * correct / total)\n",
    "            val_acc_return.append(acc)\n",
    "            val_loss_every_epoch = np.average(val_loss_list)\n",
    "            val_loss_return.append(val_loss_every_epoch)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model_wts = model.state_dict()\n",
    "            elapse = time.strftime('%H:%M:%S', time.gmtime(int((time.time() - start_time))))\n",
    "            print('Test set | Loss: {:6.4f} | Accuracy: {:4.2f}% | time elapse: {:>9}'.format(val_loss_every_epoch, acc,elapse))\n",
    "    return model,train_loss_return,train_acc_return,val_loss_return,val_acc_return,best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_BERT = transformers.modeling_bert.BertForSequenceClassification.\\\n",
    "from_pretrained(\"bert-base-uncased\",num_labels=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Epoch 1/ 5----------\n",
      "Train set | Loss: 1.0043 | Accuracy: 60.00% \n",
      "Test set | Loss: 0.7283 | Accuracy: 67.00% | time elapse:  00:03:01\n",
      "----------Epoch 2/ 5----------\n",
      "Train set | Loss: 0.6597 | Accuracy: 70.00% \n",
      "Test set | Loss: 0.5987 | Accuracy: 67.00% | time elapse:  00:05:58\n",
      "----------Epoch 3/ 5----------\n",
      "Train set | Loss: 0.5641 | Accuracy: 70.00% \n",
      "Test set | Loss: 0.6279 | Accuracy: 67.00% | time elapse:  00:08:54\n",
      "----------Epoch 4/ 5----------\n",
      "Train set | Loss: 0.5028 | Accuracy: 74.00% \n",
      "Test set | Loss: 0.6844 | Accuracy: 63.00% | time elapse:  00:11:51\n",
      "----------Epoch 5/ 5----------\n",
      "Train set | Loss: 0.4668 | Accuracy: 75.00% \n",
      "Test set | Loss: 0.6984 | Accuracy: 68.00% | time elapse:  00:14:48\n"
     ]
    }
   ],
   "source": [
    "model,train_loss,train_acc,val_loss,val_acc,best_model_wts = train(model_BERT,num_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(train_loss,label='train loss')\n",
    "line2, = ax.plot(val_loss,label='validate loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSikfoQVdKaV8xP8D05Xb8iC59tMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "line1, = ax.plot(train_acc,label='train accuracy')\n",
    "line2, = ax.plot(val_acc,label='validate accuracy')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader=test_loader, best_model_wts = best_model_wts):\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    truths = []\n",
    "    test_loss_list = []  \n",
    "    with torch.no_grad():\n",
    "        for i, (data, data_len, masks, labels) in enumerate(test_loader):\n",
    "            data,data_len,masks,labels=data.to(device),data_len.to(device),masks.to(device),labels.to(device)\n",
    "            outputs = model(data)[0]\n",
    "            loss = model(data, attention_mask = masks, labels=labels)[0]\n",
    "            test_loss_list.append(loss.item())\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            predictions += list(pred.cpu().numpy())\n",
    "            truths += list(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum()\n",
    "        acc = (100 * correct / total)\n",
    "        avg_test_loss = np.average(test_loss_list)\n",
    "        print('Test set | Loss: {:6.4f} | Accuracy: {:4.2f}% '.format(avg_test_loss, acc))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set | Loss: 0.7234 | Accuracy: 65.00% \n"
     ]
    }
   ],
   "source": [
    "test(model_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**3.7) (Bonus maximum 10 points)** List 5 examples on the test set that BERT misclassified. Describe reasons identified for misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Some misclassificated transcription exceed 512 words, only part of informations are taken from BERT model. \n",
    "\n",
    "2. Some misclassificated transcription correspond to multiple medical specialty. Sample 317 can be assigned as 'Consult - History and Phy.' or 'Orthopedic', while ture label is 'Consult - History and Phy.' and prediction is 'Orthopedic'. \n",
    "\n",
    "3. Some misclassificated transcription contains key words from other medical specialty, it may lead to misclassification.\n",
    "\n",
    "Examples are list below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BERT_test_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer = tokenizer, label = 'label'):\n",
    "        self.df = df\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.loc[idx, 'transcription']\n",
    "        tokens_query = self.tokenizer.tokenize(text)\n",
    "        tokens_query = tokens_query[:510]\n",
    "        word_pieces = [\"[CLS]\"] + tokens_query + [\"[SEP]\"]\n",
    "        ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        item_label = self.df.loc[idx, self.label]\n",
    "        id_ = idx\n",
    "        return (tokens_tensor,item_label,id_)\n",
    "    \n",
    "def pad_collate(batch):\n",
    "    (xx, yy, zz) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    tokens_tensors = pad_sequence(xx, batch_first=True)\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "    return torch.as_tensor(tokens_tensors), torch.as_tensor(x_lens), masks_tensors, torch.LongTensor(yy), zz\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "test_loader = DataLoader(BERT_test_Dataset(test_data),\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         collate_fn = pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def misclassification(model, test_loader=test_loader, best_model_wts = best_model_wts):\n",
    "    misclassification_idx = {}\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (data, data_len, masks, labels, idx) in enumerate(test_loader):\n",
    "            data,data_len,masks,labels=data.to(device),data_len.to(device),masks.to(device),labels.to(device)\n",
    "            outputs = model(data)[0]\n",
    "            pred = outputs.data.max(-1)[1]\n",
    "            if pred!=labels:\n",
    "                misclassification_idx[idx[0]]=(labels.cpu().numpy()[0],pred.cpu().numpy()[0])\n",
    "    return misclassification_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misclassification_idx = misclassification(model_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of transcription in ten random misclassification samples: 627, 489, 276, 543, 593, 146, 885, 670, 718, 234, "
     ]
    }
   ],
   "source": [
    "print('Length of transcription in ten random misclassification samples:',end=' ')\n",
    "for i in list(misclassification_idx.keys())[:10]:\n",
    "    print(len(df.iloc[i]['transcription'].split()),end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "Sample index: 317\n",
      "Label:  Consult - History and Phy.\n",
      "Prediction:  Orthopedic\n",
      "PREOPERATIVE DIAGNOSIS: , Left tibial tubercle avulsion fracture.,POSTOPERATIVE DIAGNOSIS:,  Comminuted left tibial tubercle avulsion fracture with intraarticular extension.,PROCEDURE:,  Open reduction and internal fixation of left tibia.,ANESTHESIA: , General.  The patient received 10 ml of 0.5% Marcaine local anesthetic.,TOURNIQUET TIME: , 80 minutes.,ESTIMATED BLOOD LOSS:,  Minimal.,DRAINS: , One JP drain was placed.,COMPLICATIONS: , No intraoperative complications or specimens.  Hardware consisted of two 4-5 K-wires, One 6.5, 60 mm partially threaded cancellous screw and one 45, 60 mm partially threaded cortical screw and 2 washers.,HISTORY AND PHYSICAL:,  The patient is a 14-year-old male who reported having knee pain for 1 month.  Apparently while he was playing basketball on 12/22/2007 when he had gone up for a jump, he felt a pop in his knee.  The patient was seen at an outside facility where he was splinted and subsequently referred to Children's for definitive care.  Radiographs confirmed comminuted tibial tubercle avulsion fracture with patella alta.  Surgery is recommended to the grandmother and subsequently to the father by phone.  Surgery would consist of open reduction and internal fixation with subsequent need for later hardware removal.  Risks of surgery include the risks of  anesthesia, infection, bleeding, changes on sensation in most of the extremity, hardware failure, need for later hardware removal, failure to restore extensor mechanism tension, and need for postoperative rehab.  All questions were answered, and father and grandmother agreed to the above plan.,PROCEDURE: , The patient was taken to the operating and placed supine on the operating table.  General anesthesia was then administered.  The patient was given Ancef preoperatively.  A nonsterile tourniquet was placed on the upper aspect of the patient's left thigh.  The patient's extremity was then prepped and draped in the standard surgical fashion.  Midline incision was marked on the skin extending from the tibial tubercle proximally and extremities wrapped in Esmarch.  Finally, the patient had tourniquet that turned in 75 mmHg.  Esmarch was then removed.  The incision was then made.  The patient had significant  tearing of the posterior retinaculum medially with proximal migration of the tibial tubercle which was located in the joint there was a significant comminution and intraarticular involvement.  We were able to see the underside of the anterior horn of both medial and lateral meniscus.  The intraarticular cartilage was restored using two 45 K-wires.  Final position was checked via fluoroscopy and the corners were buried in the cartilage.  There was a large free floating metaphyseal piece that included parts of proximal tibial physis.  This was placed back in an anatomic location and fixed using a 45 cortical screw with a washer.  The avulsed fragment with the patellar tendon was then fixed distally to this area using a 6.5, 60 mm cancellous screw with a washer.  The cortical screw did not provide good compression and fixation at this distal fragment.  Retinaculum was repaired using 0 Vicryl suture as best as possible.  The hematoma was evacuated at the beginning of the case as well as the end.  The knee was copiously irrigated with normal saline.  The subcutaneous tissue was re-approximated using 2-0 Vicryl and the skin with 4-0 Monocryl.  The wound was cleaned, dried, and dressed with Steri-Strips, Xeroform, and 4 x4s.  Tourniquet was released at 80 minutes.  JP drain was placed on the medium gutter.  The extremity was then wrapped in Ace wrap from the proximal thigh down to the toes.  The patient was then placed in a knee mobilizer.  The patient tolerated the procedure well.  Subsequently extubated and taken to the recovery in stable condition.,POSTOP PLAN:  ,The patient hospitalized overnight to decrease swelling and as well as manage his pain.  He may weightbear as tolerated using knee mobilizer.  Postoperative findings relayed to the grandmother.  The patient will need subsequent hardware removal.  The patient also was given local anesthetic at the end of the case.\n",
      "-------------------------------------------------------------\n",
      "Sample index: 248\n",
      "Label:  Surgery\n",
      "Prediction:  Cardiovascular / Pulmonary\n",
      "PREOPERATIVE DIAGNOSIS:,  Plantar fascitis, left foot.,POSTOPERATIVE DIAGNOSIS: , Plantar fascitis, left foot.,PROCEDURE PERFORMED: , Partial plantar fasciotomy, left foot.,ANESTHESIA:,  10 cc of 0.5% Marcaine plain with TIVA.,HISTORY:  ,This 35-year-old Caucasian female presents to ABCD General Hospital with above chief complaint.  The patient states she has extreme pain with plantar fascitis in her left foot and has attempted conservative treatment including orthotics without long-term relief of symptoms and desires surgical treatment.  The patient has been NPO since mid night.  Consent is signed and in the chart.  No known drug allergies.,Details Of Procedure:  An IV was instituted by the Department of Anesthesia in the preoperative holding area.  The patient was transported to the operating room and placed on the operating table in supine position with a safety belt across the stomach.  Copious amounts of Webril were placed on the left ankle followed by blood pressure cuff.  After adequate sedation by the Department of Anesthesia, a total of 10 cc of 0.5% Marcaine plain was injected into the surgical site both medially and laterally across the plantar fascia.  The foot was then prepped and draped in the usual sterile orthopedic fashion.  An Esmarch bandage was applied for exsanguination and the pneumatic ankle tourniquet was inflated to 250 mmHg.  The foot was then reflected on the operating, stockinet reflected, and the foot cleansed with a wet and dry sponge.  Attention was then directed to the plantar medial aspect of the left heel.  An approximately 0.75 cm incision was then created in the plantar fat pad over the area of maximal tenderness.,The incision was then deepened with a combination of sharp and blunt dissection until the plantar fascia was palpated.  A #15 blade was then used to transect the medial and central bands of the plantar fascia.  Care was taken to preserve the lateral fibroids.  The foot was dorsiflexed against resistance as the fibers were released and there was noted to be increased laxity after release of the fibers on the plantar aspect of the foot indicating that plantar fascia has in fact been transacted.  The air was then flushed with copious amounts of sterile saline.  The skin incision was then closed with #3-0 nylon in simple interrupted fashion.  Dressings consisted of #0-1 silk, 4 x 4s, Kling, Kerlix, and Coban.  The pneumatic ankle tourniquet was released and immediate hyperemic flush was noted throughout all digits of the left foot.  The patient tolerated the above procedure and anesthesia well without complications.  The patient was transported to the PACU with vital signs stable and vascular status intact to the left foot.  Intraoperatively, an additional 80 cc of 1% lidocaine was injected for additional anesthesia in the case.  The patient is to be nonweightbearing on the left lower extremity with crutches.  The patient is given postoperative pain prescriptions for Vicodin ES, one q3-4h. p.o. p.r.n. for pain as well as Celebrex 200 mg one p.o. b.i.d.  The patient is to follow-up with Dr. X as directed.\n",
      "-------------------------------------------------------------\n",
      "Sample index: 467\n",
      "Label:  Orthopedic\n",
      "Prediction:  Surgery\n",
      "PREOPERATIVE DIAGNOSIS: , Acute cholecystitis.,POSTOPERATIVE DIAGNOSIS:,  Acute cholecystitis.,PROCEDURE PERFORMED:,  Laparoscopic cholecystectomy.,ANESTHESIA: , General.,ESTIMATED BLOOD LOSS:,  Zero.,COMPLICATIONS: , None.,PROCEDURE:  ,The patient was taken to the operating room, and after obtaining adequate general anesthesia, the patient was placed in the supine position.  The abdominal area was prepped and draped in the usual sterile fashion.  A small skin incision was made below the umbilicus.  It was carried down in the transverse direction on the side of her old incision.  It was carried down to the fascia.  An open pneumoperitoneum was created with Hasson technique.  Three additional ports were placed in the usual fashion.  The gallbladder was found to be acutely inflamed, distended, and with some necrotic areas.  It was carefully retracted from the isthmus, and the cystic structure was then carefully identified, dissected, and divided between double clips.  The gallbladder was then taken down from the gallbladder fossa with electrocautery.  There was some bleeding from the gallbladder fossa that was meticulously controlled with a Bovie.  The gallbladder was then finally removed via the umbilical port with some difficulty because of the size of the gallbladder and size of the stones.  The fascia had to be opened.  The gallbladder had to be opened, and the stones had to be extracted carefully.  When it was completed, I went back to the abdomen and achieved complete hemostasis.  The ports were then removed under direct vision with the scope.  The fascia of the umbilical wound was closed with a figure-of-eight 0 Vicryl.  All the incisions were injected with 0.25% Marcaine, closed with 4-0 Monocryl, Steri-Strips, and sterile dressing.,The patient tolerated the procedure satisfactorily and was transferred to the recovery room in stable condition.\n",
      "-------------------------------------------------------------\n",
      "Sample index: 91\n",
      "Label:  Radiology\n",
      "Prediction:  Orthopedic\n",
      "POSTOPERATIVE DIAGNOSIS:,  Chronic adenotonsillitis.,PROCEDURE PERFORMED: , Tonsillectomy and adenoidectomy.,ANESTHESIA:  ,General endotracheal tube.,ESTIMATED BLOOD LOSS:,  Minimum, less than 5 cc.,SPECIMENS:,  Right and left tonsils 2+, adenoid pad 1+.  There was no adenoid specimen.,COMPLICATIONS: , None.,HISTORY: , The patient is a 9-year-old Caucasian male with history of recurrent episodes of adenotonsillitis that has been refractory to outpatient antibiotic therapy.  The patient has had approximately four to five episodes of adenotonsillitis per year for the last three to four years.,PROCEDURE: , Informed consent was properly obtained from the patient's parents and the patient was taken to the operating room #3 and was placed in a supine position.  He was placed under general endotracheal tube anesthesia by the Department of Anesthesia.  The bed was then rolled away from Department of Anesthesia.  A shoulder roll was then placed beneath the shoulder blades and a blue towel was then fashioned as a turban wrap.  The McIvor mouth gag was carefully positioned into the patient's mouth with attention to avoid the teeth.,The retractor was then opened and the oropharynx was visualized.  The adenoid pad was then visualized with a laryngeal mirror.  The adenoids appeared to be 1+ and non-obstructing.  There was no evidence of submucosal cleft palate palpable.  There was no evidence of bifid uvula.  A curved Allis clamp was then used to grasp the superior pole of the right tonsil.  The tonsil was then retracted inferiorly and medially.  Bovie cautery was used to make an incision on the mucosa of the right anterior tonsillar pillar to find the appropriate plane of dissection.  The tonsil was then dissected out within this plane using a Bovie.  Tonsillar sponge was re-applied to the tonsillar fossa.  Suction cautery was then used to adequately obtain hemostasis with the tonsillar fossa.  Attention was then directed to the left tonsil.  The curved Allis was used to grasp the superior pole of the left tonsil and it was retracted inferiorly and medially.  Bovie cautery was used to make an incision in the mucosa of the left anterior tonsillar pillar and define the appropriate plane of dissection.  The tonsil was then dissected out within this plane using the Bovie.  Next, complete hemostasis was achieved within the tonsillar fossae using suction cautery.  After adequate hemostasis was obtained, attention was directed towards the adenoid pad.  The adenoid pad was again visualized and appeared 1+ and was non-obstructing.  Decision was made to use suction cautery to cauterize the adenoids.  Using a laryngeal mirror under direct visualization, the adenoid pad was then cauterized with care to avoid the eustachian tube orifices as well as the soft palate and inferior turbinates.  After cauterization was complete, the nasopharynx was again visualized and tonsillar sponge was applied.  Adequate hemostasis was achieved.  The tonsillar fossae were again visualized and no evidence of bleeding was evident.  The throat pack was removed from the oropharynx and the oropharynx was suctioned.  There was no evidence of any further bleeding.  A flexible suction catheter was then used to suction out the nasopharynx to the oropharynx.  The suction catheter was also used to suction up the stomach.  Final look revealed no evidence of further bleeding and 10 mg of Decadron was given intraoperatively.,DISPOSITION:  ,The patient tolerated the procedure well and the patient was transported to the recovery room in stable condition.\n",
      "-------------------------------------------------------------\n",
      "Sample index: 208\n",
      "Label:  Radiology\n",
      "Prediction:  Orthopedic\n",
      "PREOPERATIVE DIAGNOSIS: , Squamous cell carcinoma of the scalp.,POSTOPERATIVE DIAGNOSIS:,  Same.,OPERATION PERFORMED: , Radical resection of tumor of the scalp (CPT 11643).  Excision of tumor from the skull with debridement of the superficial cortex with diamond bur.  Advancement flap closure, with total undermined area 18 centimeters by 16 centimeters (CPT 14300).,ANESTHESIA:,  General endotracheal anesthesia.,INDICATIONS:  ,This is an 81-year-old male who has a large exophytic 7cm lesion of the anterior midline scalp which is biopsy-positive for skin malignancy, specifically, squamous call carcinoma.  This appears to be affixed to the underlying scalp.,PLAN: , Radical resection with frozen sections to clear margins thereafter, with planned reconstruction.,CONSENT:,  I have discussed with the patient the possible risks of bleeding, infection, renal problems, scar formation, injury to muscle, nerves, and possible need for additional surgery with possible recurrence of the patient's carcinoma, with review of detailed informed consent with the patient, who understood, and wished to proceed.,FINDINGS: , The patient had a 7cm large exophytic lesion which appeared to be invasive into the superficial table of the skull.  The final periosteal margin which centrally appeared was positive for carcinoma.  The final margins peripherally were all negative.,DESCRIPTION OF PROCEDURE IN DETAIL: , The patient was taken to the operating room and there was placed supine on the operating room table.,General endotracheal anesthesia was administered after endotracheal tube intubation was performed by the Anesthesia Service personnel.  The patient was thereafter prepped and draped in the usual sterile manner using Betadine Scrub and Betadine paint.  Thereafter, the local anesthesia was injected into the area around the tumor.  A **** type excision was planned down to the periosteum.  A supraperiosteal radical resection was performed.,It was obvious that there was tumor at the deep margin, involving the periosteum.  The edges were marked along the four quadrants, at the 12 o'clock, 3 o'clock, 6 o'clock, and the 9 o'clock positions, and these were sent for frozen section evaluation.  Frozen section revealed positive margins at one end of the resection.  Therefore, an additional circumferential resection was performed and the final margins were all negative.,Following completion, the deep periosteal margin was resected.  The circumferential periosteal margins were noted to be negative; however, centrally, there was a small area which showed tumor eroding into the superficial cortex of the skull.  Therefore, the Midas Rex drill was utilized to resect approximately 1-2 mm of the superficial cortex of the bone at the area where the positive margin was located.  Healthy bone was obtained; however, it did not enter the diploic or marrow-containing bone in the area.  Therefore, no bong margin was taken.  However, at the end of the procedure, it did not appear that the residual bone had any residual changes consistent with carcinoma.,Following completion of the bony resection, the area was irrigated with copious amounts of saline.  Thereafter, advancement flaps were created, both on the left and the right side of the scalp, with the total undermined area being approximately 18cm by 16cm.  The galea was incised in multiple areas, to provide for additional mobilization of the tissue.  The tissue was closed under tension with 3-0 Vicryl suture deep in the galea and surgical staples superficially.,The patient was awakened from anesthetic, was extubated and was taken to the recovery room in stable condition.,DISPOSITION:,  The patient was discharged to home with antibiotics and analgesics, to follow-up in approximately one week.,NOTE: , The final margins of both periosteal, as well as skin were negative circumferentially, around the tumor.  The only positive margin was deep, which was a periosteal margin and bone underlying it was partially resected, as was indicated above.\n"
     ]
    }
   ],
   "source": [
    "for i in list(misclassification_idx.keys())[:5]:\n",
    "    print('-------------------------------------------------------------')\n",
    "    print('Sample index:',i)\n",
    "    print('Label:',top_5_classes[misclassification_idx[i][0]])\n",
    "    print('Prediction:',top_5_classes[misclassification_idx[i][1]])\n",
    "    print(df.iloc[i]['transcription'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
